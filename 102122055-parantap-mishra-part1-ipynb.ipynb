{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d43f89dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T14:30:38.825986Z",
     "iopub.status.busy": "2023-06-18T14:30:38.825420Z",
     "iopub.status.idle": "2023-06-18T14:30:38.840909Z",
     "shell.execute_reply": "2023-06-18T14:30:38.839546Z"
    },
    "papermill": {
     "duration": 0.025515,
     "end_time": "2023-06-18T14:30:38.844007",
     "exception": false,
     "start_time": "2023-06-18T14:30:38.818492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import PIL\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d2488c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T14:30:38.854205Z",
     "iopub.status.busy": "2023-06-18T14:30:38.853723Z",
     "iopub.status.idle": "2023-06-18T14:30:47.636937Z",
     "shell.execute_reply": "2023-06-18T14:30:47.635782Z"
    },
    "papermill": {
     "duration": 8.791682,
     "end_time": "2023-06-18T14:30:47.639860",
     "exception": false,
     "start_time": "2023-06-18T14:30:38.848178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_data=[]               #CREATING A LIST TO STORE THE IMAGE PIXEL VALUES.\n",
    "label=[]                    #CREATING THE LIST TO STORE THE LABELS OF EACH IMAGE.\n",
    "\n",
    "# **ITERATING OVER THE DATASET**\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/spider-ml-inductions-2023-task-1-part-1/trainingSet'):\n",
    "    a=str(dirname)\n",
    "    for filename in filenames:\n",
    "        if str(filename).endswith(\"a.py\") == False:\n",
    "            img=PIL.Image.open(os.path.join(dirname, filename))\n",
    "            if img is not None:\n",
    "                image_data.append(np.array(img))\n",
    "                label.append(a[-1])\n",
    "            \n",
    "image_data=np.array(image_data)/255\n",
    "label=np.array(label)\n",
    "final_output=[[1,0,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0,0],[0,0,0,1,0,0,0,0,0,0],[0,0,0,0,1,0,0,0,0,0],[0,0,0,0,0,1,0,0,0,0],[0,0,0,0,0,0,1,0,0,0],[0,0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,0,1,0],[0,0,0,0,0,0,0,0,0,1]]\n",
    "one_hot_encoded_vector=[]\n",
    "for i in label:\n",
    "    \n",
    "    index=int(i)\n",
    "    one_hot_encoded_vector.append(final_output[index])\n",
    "one_hot_encoded_vector=np.array(one_hot_encoded_vector)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a9cda0",
   "metadata": {
    "papermill": {
     "duration": 0.00313,
     "end_time": "2023-06-18T14:30:47.646608",
     "exception": false,
     "start_time": "2023-06-18T14:30:47.643478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "LOADING THE TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "725304f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T14:30:47.655007Z",
     "iopub.status.busy": "2023-06-18T14:30:47.654598Z",
     "iopub.status.idle": "2023-06-18T14:30:49.803692Z",
     "shell.execute_reply": "2023-06-18T14:30:49.801847Z"
    },
    "papermill": {
     "duration": 2.156478,
     "end_time": "2023-06-18T14:30:49.806399",
     "exception": false,
     "start_time": "2023-06-18T14:30:47.649921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_data_1=[]               #CREATING A LIST TO STORE THE IMAGE PIXEL VALUES.\n",
    "label_1=[]                    #CREATING THE LIST TO STORE THE LABELS OF EACH IMAGE.\n",
    "\n",
    "# **ITERATING OVER THE DATASET**\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/spider-ml-inductions-2023-task-1-part-1/test_set'):\n",
    "    for filename in filenames:\n",
    "        if str(filename).endswith(\"a.py\") == False:\n",
    "            img=PIL.Image.open(os.path.join(dirname, filename))\n",
    "            if img is not None:\n",
    "                image_data_1.append(np.array(img)/255)\n",
    "                \n",
    "            \n",
    "image_data_1=np.array(image_data_1)\n",
    "#label_1=np.array(label_1)\n",
    "#final_output=[[1,0,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0,0],[0,0,0,1,0,0,0,0,0,0],[0,0,0,0,1,0,0,0,0,0],[0,0,0,0,0,1,0,0,0,0],[0,0,0,0,0,0,1,0,0,0],[0,0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,0,1,0],[0,0,0,0,0,0,0,0,0,1]]\n",
    "#one_hot_encoded_vector=[]\n",
    "#for i in label:\n",
    "    \n",
    " #   index=int(i)\n",
    "  #  one_hot_encoded_vector.append(final_output[index])\n",
    "#one_hot_encoded_vector=np.array(one_hot_encoded_vector) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c00bfa",
   "metadata": {
    "papermill": {
     "duration": 0.003024,
     "end_time": "2023-06-18T14:30:49.812955",
     "exception": false,
     "start_time": "2023-06-18T14:30:49.809931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "CREATING THE CLASS TO MAKE THE LAYERS OF THE NEURAL NETWORK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12848030",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T14:30:49.822033Z",
     "iopub.status.busy": "2023-06-18T14:30:49.821010Z",
     "iopub.status.idle": "2023-06-18T14:30:58.047881Z",
     "shell.execute_reply": "2023-06-18T14:30:58.046771Z"
    },
    "papermill": {
     "duration": 8.235186,
     "end_time": "2023-06-18T14:30:58.051384",
     "exception": false,
     "start_time": "2023-06-18T14:30:49.816198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.1299,ACCURACY :11.559999999999999 \n",
      "Epoch 2/100, Loss: 0.1200,ACCURACY :11.08 \n",
      "Epoch 3/100, Loss: 0.1121,ACCURACY :9.8 \n",
      "Epoch 4/100, Loss: 0.1085,ACCURACY :11.799999999999999 \n",
      "Epoch 5/100, Loss: 0.1052,ACCURACY :12.24 \n",
      "Epoch 6/100, Loss: 0.1034,ACCURACY :13.600000000000001 \n",
      "Epoch 7/100, Loss: 0.1008,ACCURACY :14.56 \n",
      "Epoch 8/100, Loss: 0.1000,ACCURACY :16.08 \n",
      "Epoch 9/100, Loss: 0.0969,ACCURACY :17.44 \n",
      "Epoch 10/100, Loss: 0.0962,ACCURACY :20.48 \n",
      "Epoch 11/100, Loss: 0.0943,ACCURACY :16.88 \n",
      "Epoch 12/100, Loss: 0.0943,ACCURACY :21.2 \n",
      "Epoch 13/100, Loss: 0.0946,ACCURACY :13.639999999999999 \n",
      "Epoch 14/100, Loss: 0.0961,ACCURACY :17.24 \n",
      "Epoch 15/100, Loss: 0.0921,ACCURACY :19.24 \n",
      "Epoch 16/100, Loss: 0.0897,ACCURACY :20.72 \n",
      "Epoch 17/100, Loss: 0.0892,ACCURACY :21.48 \n",
      "Epoch 18/100, Loss: 0.0894,ACCURACY :21.92 \n",
      "Epoch 19/100, Loss: 0.0874,ACCURACY :23.44 \n",
      "Epoch 20/100, Loss: 0.0865,ACCURACY :24.88 \n",
      "Epoch 21/100, Loss: 0.0874,ACCURACY :23.04 \n",
      "Epoch 22/100, Loss: 0.0884,ACCURACY :22.36 \n",
      "Epoch 23/100, Loss: 0.0886,ACCURACY :23.64 \n",
      "Epoch 24/100, Loss: 0.0866,ACCURACY :21.279999999999998 \n",
      "Epoch 25/100, Loss: 0.0860,ACCURACY :26.400000000000002 \n",
      "Epoch 26/100, Loss: 0.0866,ACCURACY :22.040000000000003 \n",
      "Epoch 27/100, Loss: 0.0850,ACCURACY :25.759999999999998 \n",
      "Epoch 28/100, Loss: 0.0865,ACCURACY :21.560000000000002 \n",
      "Epoch 29/100, Loss: 0.0845,ACCURACY :26.279999999999998 \n",
      "Epoch 30/100, Loss: 0.0848,ACCURACY :21.92 \n",
      "Epoch 31/100, Loss: 0.0837,ACCURACY :26.240000000000002 \n",
      "Epoch 32/100, Loss: 0.0839,ACCURACY :25.759999999999998 \n",
      "Epoch 33/100, Loss: 0.0852,ACCURACY :23.919999999999998 \n",
      "Epoch 34/100, Loss: 0.0821,ACCURACY :28.96 \n",
      "Epoch 35/100, Loss: 0.0846,ACCURACY :25.840000000000003 \n",
      "Epoch 36/100, Loss: 0.0814,ACCURACY :29.56 \n",
      "Epoch 37/100, Loss: 0.0809,ACCURACY :26.96 \n",
      "Epoch 38/100, Loss: 0.0809,ACCURACY :32.4 \n",
      "Epoch 39/100, Loss: 0.0796,ACCURACY :33.68 \n",
      "Epoch 40/100, Loss: 0.0809,ACCURACY :31.96 \n",
      "Epoch 41/100, Loss: 0.0795,ACCURACY :34.52 \n",
      "Epoch 42/100, Loss: 0.0814,ACCURACY :34.8 \n",
      "Epoch 43/100, Loss: 0.0800,ACCURACY :34.48 \n",
      "Epoch 44/100, Loss: 0.0796,ACCURACY :35.96 \n",
      "Epoch 45/100, Loss: 0.0792,ACCURACY :35.44 \n",
      "Epoch 46/100, Loss: 0.0813,ACCURACY :32.12 \n",
      "Epoch 47/100, Loss: 0.0804,ACCURACY :35.24 \n",
      "Epoch 48/100, Loss: 0.0788,ACCURACY :35.88 \n",
      "Epoch 49/100, Loss: 0.0785,ACCURACY :36.08 \n",
      "Epoch 50/100, Loss: 0.0809,ACCURACY :33.239999999999995 \n",
      "Epoch 51/100, Loss: 0.0796,ACCURACY :34.48 \n",
      "Epoch 52/100, Loss: 0.0779,ACCURACY :34.36 \n",
      "Epoch 53/100, Loss: 0.0786,ACCURACY :33.32 \n",
      "Epoch 54/100, Loss: 0.0780,ACCURACY :33.76 \n",
      "Epoch 55/100, Loss: 0.0786,ACCURACY :33.6 \n",
      "Epoch 56/100, Loss: 0.0784,ACCURACY :33.839999999999996 \n",
      "Epoch 57/100, Loss: 0.0810,ACCURACY :28.28 \n",
      "Epoch 58/100, Loss: 0.0805,ACCURACY :30.8 \n",
      "Epoch 59/100, Loss: 0.0809,ACCURACY :29.12 \n",
      "Epoch 60/100, Loss: 0.0786,ACCURACY :33.239999999999995 \n",
      "Epoch 61/100, Loss: 0.0803,ACCURACY :27.279999999999998 \n",
      "Epoch 62/100, Loss: 0.0896,ACCURACY :21.52 \n",
      "Epoch 63/100, Loss: 0.0847,ACCURACY :29.32 \n",
      "Epoch 64/100, Loss: 0.0814,ACCURACY :28.360000000000003 \n",
      "Epoch 65/100, Loss: 0.0839,ACCURACY :29.84 \n",
      "Epoch 66/100, Loss: 0.0782,ACCURACY :28.560000000000002 \n",
      "Epoch 67/100, Loss: 0.0773,ACCURACY :30.56 \n",
      "Epoch 68/100, Loss: 0.0763,ACCURACY :31.44 \n",
      "Epoch 69/100, Loss: 0.0763,ACCURACY :31.680000000000003 \n",
      "Epoch 70/100, Loss: 0.0758,ACCURACY :31.919999999999998 \n",
      "Epoch 71/100, Loss: 0.0763,ACCURACY :32.440000000000005 \n",
      "Epoch 72/100, Loss: 0.0771,ACCURACY :31.96 \n",
      "Epoch 73/100, Loss: 0.0792,ACCURACY :29.24 \n",
      "Epoch 74/100, Loss: 0.0757,ACCURACY :32.879999999999995 \n",
      "Epoch 75/100, Loss: 0.0760,ACCURACY :32.519999999999996 \n",
      "Epoch 76/100, Loss: 0.0762,ACCURACY :34.08 \n",
      "Epoch 77/100, Loss: 0.0758,ACCURACY :33.2 \n",
      "Epoch 78/100, Loss: 0.0784,ACCURACY :32.56 \n",
      "Epoch 79/100, Loss: 0.0758,ACCURACY :34.04 \n",
      "Epoch 80/100, Loss: 0.0773,ACCURACY :33.96 \n",
      "Epoch 81/100, Loss: 0.0754,ACCURACY :36.720000000000006 \n",
      "Epoch 82/100, Loss: 0.0789,ACCURACY :32.32 \n",
      "Epoch 83/100, Loss: 0.0781,ACCURACY :33.68 \n",
      "Epoch 84/100, Loss: 0.0734,ACCURACY :37.72 \n",
      "Epoch 85/100, Loss: 0.0743,ACCURACY :38.68 \n",
      "Epoch 86/100, Loss: 0.0729,ACCURACY :39.64 \n",
      "Epoch 87/100, Loss: 0.0738,ACCURACY :38.92 \n",
      "Epoch 88/100, Loss: 0.0718,ACCURACY :40.8 \n",
      "Epoch 89/100, Loss: 0.0744,ACCURACY :39.24 \n",
      "Epoch 90/100, Loss: 0.0730,ACCURACY :39.160000000000004 \n",
      "Epoch 91/100, Loss: 0.0713,ACCURACY :40.760000000000005 \n",
      "Epoch 92/100, Loss: 0.0787,ACCURACY :36.4 \n",
      "Epoch 93/100, Loss: 0.0772,ACCURACY :35.6 \n",
      "Epoch 94/100, Loss: 0.0720,ACCURACY :39.56 \n",
      "Epoch 95/100, Loss: 0.0766,ACCURACY :35.08 \n",
      "Epoch 96/100, Loss: 0.0717,ACCURACY :41.64 \n",
      "Epoch 97/100, Loss: 0.0714,ACCURACY :41.52 \n",
      "Epoch 98/100, Loss: 0.0703,ACCURACY :41.52 \n",
      "Epoch 99/100, Loss: 0.0694,ACCURACY :41.8 \n",
      "Epoch 100/100, Loss: 0.0692,ACCURACY :43.24 \n",
      "[ 79 372  62 595 318 430 215 282   1 279]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 79, 372,  62, 595, 318, 430, 215, 282,   1, 279])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.weights_hidden1 = np.random.randn(self.hidden_size[0], self.input_size)\n",
    "        self.bias_hidden1 = np.zeros((self.hidden_size[0], 1))-0.3\n",
    "        \n",
    "        self.weights_hidden2 = np.random.randn(self.hidden_size[1], self.hidden_size[0])\n",
    "        self.bias_hidden2 = np.zeros((self.hidden_size[1], 1))-0.3\n",
    "        \n",
    "        self.weights_hidden3 = np.random.randn(self.hidden_size[2], self.hidden_size[1])\n",
    "        self.bias_hidden3 = np.zeros((self.hidden_size[2], 1))-0.3\n",
    "        \n",
    "        self.weights_output = np.random.randn(self.output_size, self.hidden_size[2])\n",
    "        self.bias_output = np.zeros((self.output_size, 1))-0.3\n",
    "        \n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        x -= np.max(x, axis=0)\n",
    "        exp_vals = np.exp(x)\n",
    "        return exp_vals / np.sum(exp_vals, axis=0)\n",
    "    \n",
    "    def flatten(self, x):\n",
    "        Flattend_layer_output=[]\n",
    "        for data in x:\n",
    "            Flattend_layer_output.append(np.ravel(data))\n",
    "        return (np.array(Flattend_layer_output).T)\n",
    "    \n",
    "    def forward_propagation(self, x):\n",
    "        self.input = self.flatten(x)\n",
    "        \n",
    "        self.hidden1_input = np.dot(self.weights_hidden1, self.input) + self.bias_hidden1\n",
    "        self.hidden1_output = np.tanh(self.hidden1_input)\n",
    "        \n",
    "        self.hidden2_input = np.dot(self.weights_hidden2, self.hidden1_output) + self.bias_hidden2\n",
    "        self.hidden2_output = np.tanh(self.hidden2_input)\n",
    "        \n",
    "        self.combined_output=self.hidden2_output+self.hidden1_output\n",
    "        \n",
    "        self.hidden3_input = np.dot(self.weights_hidden3, self.combined_output) + self.bias_hidden3\n",
    "        self.hidden3_output = np.tanh(self.hidden3_input)\n",
    "        \n",
    "        self.output_input = np.dot(self.weights_output, self.hidden3_output) + self.bias_output\n",
    "        \n",
    "        self.output_output = self.softmax(self.output_input)\n",
    "        \n",
    "        \n",
    "    def mse_loss(self, predicted, target):\n",
    "        return np.mean((predicted - target)**2)\n",
    "    \n",
    "    def backpropagation(self, x, y, learning_rate):\n",
    "        m = x.shape[1]  # number of training examples\n",
    "        \n",
    "        d_loss_predicted = 2 * (self.output_output - y) / 2500\n",
    "        \n",
    "        dw_output = np.dot(d_loss_predicted, self.hidden3_output.T)\n",
    "        db_output = np.sum(d_loss_predicted, axis=1, keepdims=True)\n",
    "        \n",
    "        d_loss_hidden3 = np.dot(self.weights_output.T, d_loss_predicted)\n",
    "        d_loss_hidden3=d_loss_hidden3*(1-(np.tanh(self.hidden3_input))**2) \n",
    "        \n",
    "        dw_hidden3 = np.dot(d_loss_hidden3, self.hidden2_output.T)\n",
    "        db_hidden3 = np.sum(d_loss_hidden3, axis=1, keepdims=True)\n",
    "        \n",
    "        d_loss_hidden2 = np.dot(self.weights_hidden3.T, d_loss_hidden3)\n",
    "        d_loss_hidden2=d_loss_hidden2*(1-(np.tanh(self.hidden2_input)))\n",
    "        \n",
    "        dw_hidden2 = np.dot(d_loss_hidden2, self.hidden1_output.T)\n",
    "        db_hidden2 = np.sum(d_loss_hidden2, axis=1, keepdims=True)\n",
    "        \n",
    "        d_loss_hidden1 = np.dot(self.weights_hidden2.T, d_loss_hidden2)\n",
    "        d_loss_hidden1=d_loss_hidden1*(1-np.tanh(self.hidden1_input)**2)\n",
    "        d_loss_hidden1_to_3=np.dot(self.weights_hidden3.T,d_loss_hidden3)\n",
    "        d_loss_hidden1_to_3=d_loss_hidden1_to_3*(1-np.tanh(self.hidden1_input)**2)\n",
    "        \n",
    "        dw_hidden1 = np.dot(d_loss_hidden1, self.flatten(x).T)+np.dot(d_loss_hidden1_to_3,self.flatten(x).T)\n",
    "        db_hidden1 = np.sum(d_loss_hidden1+d_loss_hidden1_to_3, axis=1, keepdims=True)\n",
    "        \n",
    "        self.weights_output -= learning_rate * dw_output\n",
    "        self.bias_output -= learning_rate * db_output\n",
    "        \n",
    "        self.weights_hidden3 -= learning_rate * dw_hidden3\n",
    "        self.bias_hidden3 -= learning_rate * db_hidden3\n",
    "        \n",
    "        self.weights_hidden2 -= learning_rate * dw_hidden2\n",
    "        self.bias_hidden2 -= learning_rate * db_hidden2\n",
    "        \n",
    "        self.weights_hidden1 -= learning_rate * dw_hidden1\n",
    "        self.bias_hidden1 -= learning_rate * db_hidden1\n",
    "    \n",
    "    \n",
    "            \n",
    "    def predict(self, x):\n",
    "        self.forward_propagation(x)\n",
    "        return self.output_output\n",
    "    def calculate_accuracy(self,predictions, targets):\n",
    "        predicted_labels = np.argmax(predictions, axis=1)\n",
    "        true_labels = np.argmax(targets, axis=1)\n",
    "        \n",
    "    \n",
    "        correct_predictions = np.sum(np.equal(predicted_labels,true_labels))\n",
    "        total_predictions = len(targets)\n",
    "    \n",
    "        accuracy = correct_predictions / 2500\n",
    "        return accuracy\n",
    "    def train(self, x, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            self.forward_propagation(x)\n",
    "            self.backpropagation(x, y, learning_rate)\n",
    "            loss = self.mse_loss(self.output_output, y)\n",
    "            \n",
    "            \n",
    "            accuracy=self.calculate_accuracy(self.output_output.T,one_hot_encoded_vector)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f},ACCURACY :{accuracy*100} \")\n",
    "    def test(self,x):\n",
    "        self.forward_propagation(x)\n",
    "        \n",
    "        predictions=np.argmax(self.output_output,axis=1)\n",
    "        print(predictions)\n",
    "        return(predictions)\n",
    "\n",
    "\n",
    "input_size = 784\n",
    "hidden_size = [8,8,8]\n",
    "output_size = 10\n",
    "\n",
    "x = image_data\n",
    "y = one_hot_encoded_vector.T\n",
    "\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "# Train the neural network\n",
    "nn.train(x, y, epochs=100, learning_rate=0.3)\n",
    "\n",
    "# TEST THE DATASET\n",
    "nn.test(image_data_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2a7345",
   "metadata": {
    "papermill": {
     "duration": 0.013872,
     "end_time": "2023-06-18T14:30:58.079134",
     "exception": false,
     "start_time": "2023-06-18T14:30:58.065262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8e2f64",
   "metadata": {
    "papermill": {
     "duration": 0.012949,
     "end_time": "2023-06-18T14:30:58.106277",
     "exception": false,
     "start_time": "2023-06-18T14:30:58.093328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32.771375,
   "end_time": "2023-06-18T14:30:58.950526",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-18T14:30:26.179151",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
